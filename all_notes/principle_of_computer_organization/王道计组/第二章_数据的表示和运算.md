##### 如何理解进制?
进制本身就是不同位的权重体现
根据数的累积进位,所以越在前面的位其权重越高
而同时不同的进位有不同的"积蓄槽"
满足了这个积蓄槽就会向上进一位
所以在这里我们就不能以往常十进制的视角去看待这些数

比如
八进制下的96
这就不能念成九十六,应该这个十彰显了其为十进制下的数字
这是八进制,
那么应该怎么念,或者怎么理解这个数呢?

首先要理解不同进制的存在意义?
二进制的存在意义
方便表示低电压高电压,给机器看的,本身就不是给人看的
八进制,16进制的存在意义
方便表示二进制,相当于二进制的助记符
三位二进制数可以缩减为一位八进制数表示
四位二进制数可以缩减为一位16进制数


所以不同的进制存在意义仅仅是为了"表示"
其表达的"排列组合种类"总量并不会因为不同进制而不一样

##### 进制转换
八进制与十六进制互转
八进制十六进制可以先转为二进制再转成对方
同理
十进制可以先转为二进制再转八进制和十六进制
![](img/Pasted%20image%2020220829195432.png)
![](img/Pasted%20image%2020220829195454.png)

##### 进制练习
十进制转二进制

![](img/Pasted%20image%2020220829194717.png)
##### 负数该如何表示?
拿一位表示正数和负数
![](img/Pasted%20image%2020220829195504.png)

##### bcd码的存在意义?
Binary-Coded Decimal
用四个二进制数来表示0~9的十进制数
bcd码有三种实现形式
一般采用8421有的采用余3或者2421的形式编码
余3和2421的实现形式暂时不讲
就8421来说
四位二进制能表示的种类有十六种,有六个数冗余
且你4+6=10,  10不在 0~9的范围内

8421码对超过0~9范围的数该如何表示呢?
之所以用bcd码来编码表示数字就是因为可以将数字拆分为一个一个的字符去看待
那么10可以看成由1和0组成
8421码可以是0001 0000
36可以看成3和6   那么就是0011 0110

与ASCII的关系是
ASCII的后四位与8421一样
![](img/Pasted%20image%2020220829195515.png)
我们可以理解为
在计算机里用压缩过的bcd码存数字能减少空间
像java里的int一律用四个字节存数字,你不管数的大小一律四个字节
而bcd码会根据数的字符大小动态的调整占据空间
0~9范围的只占半个字节
10~99范围的占一个字节,两个四位二进制表示
100~999一个半字节(1001 1001 1001)

那么我们可以从上述的推理中总结出bcd码的存在意义了
为了给使数字占有的空间更小,且不会造成精度丢失
[精度与误差](#####精度与误差)



##### 8421码如何进行加减运算呢?
对0~9的视为字符直接转成四位二进制,不在范围内二进制数加6

比如36+14
0011 0110 + 
0001 0100 =
0100 1010
0100在0~9范围内   1010不在,对1010加6(0110)
 1010+
 0110=
10000   把这个1向上给0100
那么结果就是0101 0000 = 50!!!

##### ASCII码是干什么的?
American Standard Code for Information Interchange美国标准信息互换码
美国早期表示字符用的


##### ASCII码的组成?
![](img/Pasted%20image%2020220829195533.png)

其中包括了
* 可打印字符
* 控制字符

0到32位和最后一个127位是不可打印的不可见字符
![](img/Pasted%20image%2020220829195544.png)
其中也包括我们熟悉的ACK和SYN等计算机网络通信的字符

##### 转义字符与ASCII有什么关系?
因为上面提到了有一些ASCII表示的字符是不可见字符
但我们在输入时拿什么符号去表示我们要输入一个不可见字符呢?
我们必须用一个键盘上能找得到的按键来取表示这些我们要表达出来的
不可见字符
键盘上的按键快用光了怎么办?
加个"\\"
我们查到10号正好是换行控制符,就用\\n表示
![](img/Pasted%20image%2020220829195556.png)


详细的ASCII与转义字符对照表
![](img/Pasted%20image%2020220829195607.png)
用反斜杠也有坏处,反斜杠本身表示容易出问题
有些语言用双反斜杠表示一个反斜杠

##### 字符串如何编码表示的?
一个字符串由多个字符表示
只要区分边界就行
所以在最后面"反斜杠0"
![](img/Pasted%20image%2020220829195622.png)

上图汉字采用的gb2312-80的编码方式
gbk编码方式可以看[../../project_blog/字节与字符编码#####gb2312-80](../../project_blog/字节与字符编码#####gb2312-80)

##### 数据发送与接收该如何校验?
待施工
奇偶校验
海明码
crc冗余校验
这些到计算机网络里去学

##### 补码的作用是什么?
在二进制角度将减法转换为加法运算

因为cpu中的alu在电路设计中难以对减法进行高效的实现
所以我们要从算法上去优化
用加法代替减法
那么如何代替?

这就要引入补码和模运算的概念

什么是模运算mod?
就如同时钟,就如同螺旋,以螺旋之名!溢出就会回到原点
补码就是负数用模运算得出来的

比如-14+15
-14 = 1000 1110  第一位1表示负号
先将除符号位取反得到1111 0001
再加1得1111 0010
  1111 0010
+0000 1111
得0000 0001

由于计算时一旦到达第9位就会溢出那么就可以把2^8当做二进制运算时自带的mod
把原来的15-14变成了(15+86)%100的效果

<font color=#F09B59 style=" font-weight:bold;">简单来说就是除符号位取反加一</font>

##### unsigned变量修饰符起到什么作用?
在c中表示该变量是无符号数
一般修饰int 、char，short
无法修饰double

主要作用就是表示该变量的最高位当做位权来运算而不是用作标注正负的

##### 定点数是什么?
定点数就是小数点位置不变的数
定点数分为定点小数和定点整数
![](img/Pasted%20image%2020220829195630.png)

第一个是表示正负位
后面的就表示数的大小
整数的位权是由右到左从0依次递增
小数的位权是由左到右从-1依次下降
![](img/Pasted%20image%2020220829195657.png)

##### 补码运算的溢出问题
![](img/Pasted%20image%2020220829195707.png)

两个正数相加变负数
两个负数相加变正数

为什么会变成这样....a是正数,b是正数,两个数加在一起得到的本该是正数....但是,
为什么会变成这样呢.....
白学现场了

主要是后几位相加超越范围了,把符号位给顶掉了,因此不仅值会丢失一部分,正负号也会变
```java
public class MyDemo{
	public static void main(String args []){
		int a = 2147483647;//定义一个int型变量a的值为int型能够保存的最高值
		System.out.println(a + 1);
	}
}
```
输出的结果为-2147483648

<font color=#F09B59 style=" font-weight:bold;">补码运算时会溢出,好一点会造成精度损失,坏一点,产生巨大误差</font>

##### 精度与误差
不同于bcd码
无论是定点数还是浮点数,在其移位时往往可能会造成丢失精度
比如说你一个字节存的数
0110 0011
你向右移一位,相当于除2,由于第一位是符号位不动,
得到
0011 0001你会发现丢失一个1,值是2^0,这还不算离谱
如果你将这个原码左移一位呢?
0110 0011 =>
0100 0110  这就离谱了你算一算 
原来的值为99你乘以2以后应该是198的,但你你把最前面一位的1给挤掉了,
所以只有70少加了一个128

还有一个现象就是
过大的数超越范围,会溢出变为

[bcd码能保证精度不丢失](#####bcd码的存在意义?)

像int,float只能用来进行科学计算或工程计算，在大多数的商业计算中，一般采用java.math.BigDecimal类来进行精确计算[../../java/java基础/BigDecimal](../../java/java基础/BigDecimal)

##### 强制类型转换
简单的移位就会造成精度缺失
同样强制类型转换也会使得数变得不符合预期

![](img/Pasted%20image%2020220829195722.png)

上面由符号数向无符号数转,比如short转成unsigned short
他的位权完全就变了,最高位不再是符号位
然后注意这个定点整数在c语言里是以补码形式存储
意思是这个x变量存的不是-4321的原码,而是其取反加1的补码
-4321 => 61215

第二个例子中有符号int转有符号short
直接将高16位截掉,非常暴力,连着符号位一起给砍掉了,新的高位作为符号位

第三个例子中short转int,由于x是负值,其反码在扩展时把填充的0全部改成1(取反)

在java中int直接转byte
```java
public class 强制转换用例 {
    public static void main(String[] args) {
        int d = 200;
        byte i = (byte)d;
        System.out.println(i);
    }
 
}
```
![](img/Pasted%20image%2020220829195735.png)

从上面我们可以总结出:
<font color=#F09B59 style=" font-weight:bold;">小范围向大范围转,没影响,大范围向小范围转,会造成严重问题,正数都会变负数</font>


##### 大端模式和小端模式是什么?
因为我们的寄存器的宽度往往可能要大于一个字节
所以我们就会有一个问题----如何取多个字节
是从小地址往大地址读还是从大地址往小地址读呢?
咱们不扯那些高地址和低地址
简单来说是从前面开始读int还是从后面开始读int

当我们取一个两字节的short/四字节的int时

常用的处理器的模式
![](img/Pasted%20image%2020220829195750.png)

从上面可以看出主流如intelx86,arm都是小端模式
扩充:网络协议采用大端模式

一般大端更符合人类思维,从前往后读嘛
处理器一般采用小端模式,这样读得更快


##### 边界对齐是什么概念?
![](img/Pasted%20image%2020220829195800.png)

就是我们要有个概念就是
计算机是按字节编址的,每一个字节对应一个地址单元

当然他的寻址方式就比较多了
比如按字,半字,按字节去寻址
详细部分见操作系统
[操作系统挖坑](../../OSandLinux/OS基础/内存管理)

一个int对齐排布还是拆开排布影响到内存访问次数



##### 浮点数是什么?
浮点数的结构如下
![](img/Pasted%20image%2020220829200019.png)

四个参数来描绘一个浮点数
比如-1.222×10^6
那么阶符就是说这个阶数是正还是负
阶码就是阶数的大小

尾数就是个正常的小数,数符表示正负,后面表示数的大小
比如b=0,10;0.01001
等于0.01001×2^2
化为0.1001×2^1
真值为1.001
八位二进制表示:<font color=#66CC99 style=" font-weight:bold;">0</font>01<font color=#66CC99 style=" font-weight:bold;">0</font> 1001

比如a=0,01;1.1001
由于是负数先将尾数化为补码
1001>0110>0111
真值为-0.0111×2^1=-0.111
八位二进制表示:<font color=#66CC99 style=" font-weight:bold;">0</font>01<font color=#66CC99 style=" font-weight:bold;">1</font> 1001



##### IEEE 754是什么
一套浮点数的规定
![](img/Pasted%20image%2020220830132143.png)

说实话这个算法的推导实在是太难了,比压轴大题的推导还要难太多,太难理解,放弃...

可以理解IEEE754下,比如float,其正负号一位,阶码八位,尾数加上科学计数法省略的一位有24位
那么float能表示的数的长度就是24位
而普通整数int的表示数的长度是32位
